{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para dar inicio al laboratorio se procede a importar librerias a utilizar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pycaret.datasets import get_data\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from pycaret.regression import *\n",
    "import warnings\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'train.csv'\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# División del Data Set 80% training y 20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.sample(frac=0.8, random_state=42)\n",
    "test_data = data.drop(train_data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA y Profiling del dataset utilizando PyCaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1 = setup(data=train_data, \n",
    "             target='SalePrice', \n",
    "             session_id=2023, \n",
    "             normalize=True, \n",
    "             normalize_method='minmax', \n",
    "             transformation=True)\n",
    "\n",
    "data=  get_data(dataset='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descripción de las alertas generadas en el EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(dataset='train',  profile = True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingenieria de Caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "\n",
    "# Dividir el conjunto de datos en variables predictoras (X) y variable objetivo (y) si es necesario\n",
    "# X = data.drop('variable_objetivo', axis=1)\n",
    "# y = data['variable_objetivo']\n",
    "\n",
    "# Definir las columnas numéricas y categóricas\n",
    "numeric_features = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = data.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Construir preprocesador\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Puedes ajustar la estrategia de imputación según tus necesidades\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Puedes ajustar la estrategia de imputación según tus necesidades\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Eliminación de outliers usando Isolation Forest\n",
    "outlier_detector = IsolationForest(contamination=0.05)  # Ajusta la contaminación según sea necesario\n",
    "outliers = outlier_detector.fit_predict(data[numeric_features])\n",
    "\n",
    "# Filtrar filas sin outliers\n",
    "data = data[outliers == 1]\n",
    "\n",
    "\n",
    "# Aplicar preprocesador\n",
    "X_preprocessed = preprocessor.fit_transform(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento y selcción de Modelos Automaticamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\mile1\\anaconda3\\envs\\mlops_v2\\lib\\site-packages (1.2.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: matplotlib in c:\\users\\mile1\\anaconda3\\envs\\mlops_v2\\lib\\site-packages (3.7.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\mile1\\anaconda3\\envs\\mlops_v2\\lib\\site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\mile1\\anaconda3\\envs\\mlops_v2\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\mile1\\anaconda3\\envs\\mlops_v2\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\mile1\\anaconda3\\envs\\mlops_v2\\lib\\site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\mile1\\anaconda3\\envs\\mlops_v2\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\mile1\\anaconda3\\envs\\mlops_v2\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\mile1\\anaconda3\\envs\\mlops_v2\\lib\\site-packages (from matplotlib) (4.44.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\mile1\\anaconda3\\envs\\mlops_v2\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mile1\\anaconda3\\envs\\mlops_v2\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\mile1\\anaconda3\\envs\\mlops_v2\\lib\\site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\mile1\\anaconda3\\envs\\mlops_v2\\lib\\site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\mile1\\anaconda3\\envs\\mlops_v2\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\mile1\\anaconda3\\envs\\mlops_v2\\lib\\site-packages (from matplotlib) (6.1.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\mile1\\anaconda3\\envs\\mlops_v2\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.11.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mile1\\anaconda3\\envs\\mlops_v2\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Suponiendo que ya tienes X_preprocessed y y definidos después del preprocesamiento anterior\n",
    "\n",
    "# Dividir el conjunto de datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definir el clasificador RandomForest\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Definir la cuadrícula de hiperparámetros para buscar\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Configurar la búsqueda de cuadrícula\n",
    "grid_search = GridSearchCV(rf_classifier, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Realizar la búsqueda de cuadrícula en los datos de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener el mejor modelo y sus hiperparámetros\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "\n",
    "# Métricas de rendimiento\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_report_result = classification_report(y_test, y_pred)\n",
    "\n",
    "# Imprimir resultados\n",
    "print(\"Mejores hiperparámetros:\", best_params)\n",
    "print(\"Exactitud del modelo:\", accuracy)\n",
    "print(\"Informe de clasificación:\\n\", classification_report_result)\n",
    "\n",
    "# Mostrar la importancia de las características\n",
    "feature_importances = best_rf_model.feature_importances_\n",
    "\n",
    "# Crear un gráfico de barras para mostrar la importancia de las características\n",
    "feature_names = list(data.columns)  # Asegúrate de que el orden de las características coincida\n",
    "plt.barh(range(len(feature_importances)), feature_importances, align='center')\n",
    "plt.yticks(range(len(feature_importances)), feature_names)\n",
    "plt.xlabel('Importancia de características')\n",
    "plt.ylabel('Características')\n",
    "plt.title('Importancia de características para el modelo RandomForest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimización de Hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definir el clasificador (por ejemplo, RandomForest)\n",
    "classifier = RandomForestClassifier()\n",
    "\n",
    "# Definir la cuadrícula de hiperparámetros a buscar\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Configurar la búsqueda de cuadrícula\n",
    "grid_search = GridSearchCV(classifier, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Realizar la búsqueda de cuadrícula en los datos de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener el mejor modelo y sus hiperparámetros\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Evaluar el mejor modelo en el conjunto de prueba\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Métricas de rendimiento\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_report_result = classification_report(y_test, y_pred)\n",
    "\n",
    "# Imprimir resultados\n",
    "print(\"Mejores hiperparámetros:\", best_params)\n",
    "print(\"Exactitud del modelo:\", accuracy)\n",
    "print(\"Informe de clasificación:\\n\", classification_report_result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Investigacion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
